{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8582469,"sourceType":"datasetVersion","datasetId":5132750}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nbase_dir = \"/kaggle/input/animetitle-100/corrected_labels\"  # base directory\n\n# Collect all image paths and their associated labels (subfolder names)\nimage_paths = []\nlabels = []\n\nfor subdir, dirs, files in os.walk(base_dir):\n    for file in files:\n        if file.endswith((\".jpg\", \".jpeg\", \".png\")):  # Add other extensions if needed\n            file_path = os.path.join(subdir, file)\n            image_paths.append(file_path)\n            labels.append(os.path.basename(subdir))  # Label is the folder name\n\n# Split into train and test sets (80% train, 20% test)\ntrain_paths, test_paths, train_labels, test_labels = train_test_split(\n    image_paths, labels, test_size=0.2, random_state=42, stratify=labels\n)\n\n# Further split the training set into training and validation sets (80% train, 20% validation of the original train set)\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    train_paths, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n)\n\n# Directory names\ntrain_dir = \"Train\"\ntest_dir = \"Test\"\nval_dir = \"Validation\"\n\n# Clean up existing folders if necessary\nfor folder in [train_dir, test_dir, val_dir]:\n    if os.path.exists(folder):\n        shutil.rmtree(folder)\n\n# Recreate empty folders\nos.makedirs(train_dir)\nos.makedirs(test_dir)\nos.makedirs(val_dir)\n\n# Create subfolders based on labels for train, test, and validation sets\nunique_labels = np.unique(labels)\n\nfor label in unique_labels:\n    os.makedirs(os.path.join(train_dir, label))\n    os.makedirs(os.path.join(test_dir, label))\n    os.makedirs(os.path.join(val_dir, label))\n\n# Copy images into respective train, test, and validation folders\n\nfor train_path, train_label in zip(train_paths, train_labels):\n    dest = os.path.join(train_dir, train_label, os.path.basename(train_path))\n    shutil.copy2(train_path, dest)\n\n\nfor test_path, test_label in zip(test_paths, test_labels):\n    dest = os.path.join(test_dir, test_label, os.path.basename(test_path))\n    shutil.copy2(test_path, dest)\n\n\nfor val_path, val_label in zip(val_paths, val_labels):\n    dest = os.path.join(val_dir, val_label, os.path.basename(val_path))\n    shutil.copy2(val_path, dest)\n\nprint(\"Data has been split and copied to Train, Test, and Validation directories.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-08T07:26:13.712068Z","iopub.execute_input":"2024-06-08T07:26:13.712451Z","iopub.status.idle":"2024-06-08T07:27:13.548855Z","shell.execute_reply.started":"2024-06-08T07:26:13.712423Z","shell.execute_reply":"2024-06-08T07:27:13.547579Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Data has been split and copied to Train, Test, and Validation directories.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\nimport zipfile\n\n# Function to zip directories\ndef zipdir(dir_path, ziph):\n    # ziph is zipfile handle\n    for root, _, files in os.walk(dir_path):\n        for file in files:\n            ziph.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(dir_path, '..')))\n\n# Main code\ntrain_dir = \"Train\"\ntest_dir = \"Test\"\nval_dir = \"Validation\"\n\n# Create a temporary directory to store the zip file\ntemp_dir = \"temp_zip\"\nos.makedirs(temp_dir)\n\n# Zip each directory\nwith zipfile.ZipFile(\"data_split.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n    zipdir(train_dir, zipf)\n    zipdir(test_dir, zipf)\n    zipdir(val_dir, zipf)\n\n# Remove temporary directory\nshutil.rmtree(temp_dir)\n\nprint(\"Data has been zipped and is ready for download as 'data_split.zip'.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T07:28:57.645560Z","iopub.execute_input":"2024-06-08T07:28:57.646003Z","iopub.status.idle":"2024-06-08T07:29:36.681929Z","shell.execute_reply.started":"2024-06-08T07:28:57.645973Z","shell.execute_reply":"2024-06-08T07:29:36.680646Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Data has been zipped and is ready for download as 'data_split.zip'.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}